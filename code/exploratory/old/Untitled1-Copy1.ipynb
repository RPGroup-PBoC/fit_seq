{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ccb822e-296f-426c-959c-11be781a6ce6",
   "metadata": {},
   "source": [
    "# Tetracycline Resistance Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71b51fb-f313-4d53-8755-213680c3db0d",
   "metadata": {},
   "source": [
    "(c) 2021 Tom Röschinger. This work is licensed under a \n",
    "[Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). \n",
    "All code contained herein is licensed under an \n",
    "[MIT license](https://opensource.org/licenses/MIT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b8fd92-1cd7-4972-9c9e-5c1fe66ddebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "using SymPy, Polynomials, Jedi, ColorSchemes, Turing, Distributions, LinearAlgebra\n",
    "\n",
    "# Comment this out if Jedi.jl is not installed\n",
    "#Jedi.default_gr!()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ca2ab-5edf-41d8-b0a2-9f0438dff58d",
   "metadata": {},
   "source": [
    "In this notebook we go through everything bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04d93f6-a8f4-4d5e-b462-c9d07ae7c42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(a, λ, λ_0, κ_t, K_d, Δr, j, V_0, a_ex, K_M, P_out, P_in)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@syms a λ λ_0 κ_t K_d Δr j V_0 a_ex K_M P_out P_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "febf9ac8-498c-44c9-828e-c4bcb2480907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\begin{equation*}- Δr \\left(- \\frac{λ}{λ_{0}} + 1\\right) + \\frac{a λ}{K_{d} κ_{t}}\\end{equation*}$\n"
      ],
      "text/plain": [
       "     ⎛  λ     ⎞    a⋅λ  \n",
       "- Δr⋅⎜- ── + 1⎟ + ──────\n",
       "     ⎝  λ₀    ⎠   K_d⋅κₜ"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq1 = (a * λ) / (κ_t * K_d) - Δr * (1 - λ/λ_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dbdb7624-c4af-494d-99f1-d8dc5ea7b303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\begin{equation*}K_{M} P_{in} a_{ex} + a^{2} \\left(- P_{out} - λ\\right) + a \\left(- K_{M} P_{out} - K_{M} λ + P_{in} a_{ex} - \\frac{V_{0} λ}{λ_{0}}\\right)\\end{equation*}$\n"
      ],
      "text/plain": [
       "               2                 ⎛                              V₀⋅λ⎞\n",
       "K_M⋅Pᵢₙ⋅aₑₓ + a ⋅(-Pₒᵤₜ - λ) + a⋅⎜-K_M⋅Pₒᵤₜ - K_M⋅λ + Pᵢₙ⋅aₑₓ - ────⎟\n",
       "                                 ⎝                               λ₀ ⎠"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq2 = a^2 * (-λ - P_out) + a * (-λ * K_M  + P_in * a_ex - P_out * K_M - V_0 * λ/λ_0 ) + P_in * a_ex * K_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2aa1f909-54e0-4065-8d74-9bdc88197a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\begin{equation*}\\frac{K_{d} Δr κ_{t} \\left(- λ + λ_{0}\\right)}{λ λ_{0}}\\end{equation*}$\n"
      ],
      "text/plain": [
       "K_d⋅Δr⋅κₜ⋅(-λ + λ₀)\n",
       "───────────────────\n",
       "        λ⋅λ₀       "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr1 = solve(eq1, a)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3be1138e-c9ef-4d09-a1ee-aec4e4cf4ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\begin{equation*}K_{M} P_{in} a_{ex} + \\frac{K_{d}^{2} Δr^{2} κ_{t}^{2} \\left(- P_{out} - λ\\right) \\left(- λ + λ_{0}\\right)^{2}}{λ^{2} λ_{0}^{2}} + \\frac{K_{d} Δr κ_{t} \\left(- λ + λ_{0}\\right) \\left(- K_{M} P_{out} - K_{M} λ + P_{in} a_{ex} - \\frac{V_{0} λ}{λ_{0}}\\right)}{λ λ_{0}}\\end{equation*}$\n"
      ],
      "text/plain": [
       "                                                                        ⎛     \n",
       "                 2   2   2                      2   K_d⋅Δr⋅κₜ⋅(-λ + λ₀)⋅⎜-K_M⋅\n",
       "              K_d ⋅Δr ⋅κₜ ⋅(-Pₒᵤₜ - λ)⋅(-λ + λ₀)                        ⎝     \n",
       "K_M⋅Pᵢₙ⋅aₑₓ + ─────────────────────────────────── + ──────────────────────────\n",
       "                              2   2                                           \n",
       "                             λ ⋅λ₀                                            \n",
       "\n",
       "                         V₀⋅λ⎞\n",
       "Pₒᵤₜ - K_M⋅λ + Pᵢₙ⋅aₑₓ - ────⎟\n",
       "                          λ₀ ⎠\n",
       "──────────────────────────────\n",
       "λ⋅λ₀                          \n",
       "                              "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr2 = subs(eq2, a=>expr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c013e50e-0092-4bf1-910d-b54751b21aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\begin{equation*}λ^{2} λ_{0}^{2} \\left(K_{M} P_{in} a_{ex} + \\frac{K_{d}^{2} Δr^{2} κ_{t}^{2} \\left(- P_{out} - λ\\right) \\left(- λ + λ_{0}\\right)^{2}}{λ^{2} λ_{0}^{2}} + \\frac{K_{d} Δr κ_{t} \\left(- λ + λ_{0}\\right) \\left(- K_{M} P_{out} - K_{M} λ + P_{in} a_{ex} - \\frac{V_{0} λ}{λ_{0}}\\right)}{λ λ_{0}}\\right)\\end{equation*}$\n"
      ],
      "text/plain": [
       "       ⎛                                                                      \n",
       "       ⎜                 2   2   2                      2   K_d⋅Δr⋅κₜ⋅(-λ + λ₀\n",
       " 2   2 ⎜              K_d ⋅Δr ⋅κₜ ⋅(-Pₒᵤₜ - λ)⋅(-λ + λ₀)                      \n",
       "λ ⋅λ₀ ⋅⎜K_M⋅Pᵢₙ⋅aₑₓ + ─────────────────────────────────── + ──────────────────\n",
       "       ⎜                              2   2                                   \n",
       "       ⎝                             λ ⋅λ₀                                    \n",
       "\n",
       "  ⎛                              V₀⋅λ⎞⎞\n",
       ")⋅⎜-K_M⋅Pₒᵤₜ - K_M⋅λ + Pᵢₙ⋅aₑₓ - ────⎟⎟\n",
       "  ⎝                               λ₀ ⎠⎟\n",
       "──────────────────────────────────────⎟\n",
       "        λ⋅λ₀                          ⎟\n",
       "                                      ⎠"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr3 = expr2 * λ^2 * λ_0^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b591a88-cfab-4ebe-9bf3-b13e6e50be4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\begin{equation*}K_{M} K_{d} P_{out} Δr κ_{t} λ^{2} λ_{0} - K_{M} K_{d} P_{out} Δr κ_{t} λ λ_{0}^{2} + K_{M} K_{d} Δr κ_{t} λ^{3} λ_{0} - K_{M} K_{d} Δr κ_{t} λ^{2} λ_{0}^{2} + K_{M} P_{in} a_{ex} λ^{2} λ_{0}^{2} - K_{d}^{2} P_{out} Δr^{2} κ_{t}^{2} λ^{2} + 2 K_{d}^{2} P_{out} Δr^{2} κ_{t}^{2} λ λ_{0} - K_{d}^{2} P_{out} Δr^{2} κ_{t}^{2} λ_{0}^{2} - K_{d}^{2} Δr^{2} κ_{t}^{2} λ^{3} + 2 K_{d}^{2} Δr^{2} κ_{t}^{2} λ^{2} λ_{0} - K_{d}^{2} Δr^{2} κ_{t}^{2} λ λ_{0}^{2} - K_{d} P_{in} a_{ex} Δr κ_{t} λ^{2} λ_{0} + K_{d} P_{in} a_{ex} Δr κ_{t} λ λ_{0}^{2} + K_{d} V_{0} Δr κ_{t} λ^{3} - K_{d} V_{0} Δr κ_{t} λ^{2} λ_{0}\\end{equation*}$\n"
      ],
      "text/plain": [
       "                    2                             2                  3        \n",
       "K_M⋅K_d⋅Pₒᵤₜ⋅Δr⋅κₜ⋅λ ⋅λ₀ - K_M⋅K_d⋅Pₒᵤₜ⋅Δr⋅κₜ⋅λ⋅λ₀  + K_M⋅K_d⋅Δr⋅κₜ⋅λ ⋅λ₀ - K_\n",
       "\n",
       "             2   2                2   2      2        2   2  2        2       \n",
       "M⋅K_d⋅Δr⋅κₜ⋅λ ⋅λ₀  + K_M⋅Pᵢₙ⋅aₑₓ⋅λ ⋅λ₀  - K_d ⋅Pₒᵤₜ⋅Δr ⋅κₜ ⋅λ  + 2⋅K_d ⋅Pₒᵤₜ⋅Δ\n",
       "\n",
       " 2   2           2        2   2   2      2   2   2  3        2   2   2  2     \n",
       "r ⋅κₜ ⋅λ⋅λ₀ - K_d ⋅Pₒᵤₜ⋅Δr ⋅κₜ ⋅λ₀  - K_d ⋅Δr ⋅κₜ ⋅λ  + 2⋅K_d ⋅Δr ⋅κₜ ⋅λ ⋅λ₀ -\n",
       "\n",
       "    2   2   2     2                      2                            2       \n",
       " K_d ⋅Δr ⋅κₜ ⋅λ⋅λ₀  - K_d⋅Pᵢₙ⋅aₑₓ⋅Δr⋅κₜ⋅λ ⋅λ₀ + K_d⋅Pᵢₙ⋅aₑₓ⋅Δr⋅κₜ⋅λ⋅λ₀  + K_d⋅\n",
       "\n",
       "          3                 2   \n",
       "V₀⋅Δr⋅κₜ⋅λ  - K_d⋅V₀⋅Δr⋅κₜ⋅λ ⋅λ₀"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr4 = factor(expr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b245d82-2d91-4a63-9dfb-7ca833aadf29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\begin{equation*}- K_{d}^{2} P_{out} Δr^{2} κ_{t}^{2} λ_{0}^{2} + λ^{3} \\left(K_{M} K_{d} Δr κ_{t} λ_{0} - K_{d}^{2} Δr^{2} κ_{t}^{2} + K_{d} V_{0} Δr κ_{t}\\right) + λ^{2} \\left(K_{M} K_{d} P_{out} Δr κ_{t} λ_{0} - K_{M} K_{d} Δr κ_{t} λ_{0}^{2} + K_{M} P_{in} a_{ex} λ_{0}^{2} - K_{d}^{2} P_{out} Δr^{2} κ_{t}^{2} + 2 K_{d}^{2} Δr^{2} κ_{t}^{2} λ_{0} - K_{d} P_{in} a_{ex} Δr κ_{t} λ_{0} - K_{d} V_{0} Δr κ_{t} λ_{0}\\right) + λ \\left(- K_{M} K_{d} P_{out} Δr κ_{t} λ_{0}^{2} + 2 K_{d}^{2} P_{out} Δr^{2} κ_{t}^{2} λ_{0} - K_{d}^{2} Δr^{2} κ_{t}^{2} λ_{0}^{2} + K_{d} P_{in} a_{ex} Δr κ_{t} λ_{0}^{2}\\right)\\end{equation*}$\n"
      ],
      "text/plain": [
       "     2        2   2   2    3 ⎛                      2   2   2               ⎞ \n",
       "- K_d ⋅Pₒᵤₜ⋅Δr ⋅κₜ ⋅λ₀  + λ ⋅⎝K_M⋅K_d⋅Δr⋅κₜ⋅λ₀ - K_d ⋅Δr ⋅κₜ  + K_d⋅V₀⋅Δr⋅κₜ⎠ \n",
       "\n",
       "   2 ⎛                                        2                 2      2      \n",
       "+ λ ⋅⎝K_M⋅K_d⋅Pₒᵤₜ⋅Δr⋅κₜ⋅λ₀ - K_M⋅K_d⋅Δr⋅κₜ⋅λ₀  + K_M⋅Pᵢₙ⋅aₑₓ⋅λ₀  - K_d ⋅Pₒᵤₜ⋅\n",
       "\n",
       "  2   2        2   2   2                                            ⎞     ⎛   \n",
       "Δr ⋅κₜ  + 2⋅K_d ⋅Δr ⋅κₜ ⋅λ₀ - K_d⋅Pᵢₙ⋅aₑₓ⋅Δr⋅κₜ⋅λ₀ - K_d⋅V₀⋅Δr⋅κₜ⋅λ₀⎠ + λ⋅⎝- K\n",
       "\n",
       "                    2        2        2   2         2   2   2   2             \n",
       "_M⋅K_d⋅Pₒᵤₜ⋅Δr⋅κₜ⋅λ₀  + 2⋅K_d ⋅Pₒᵤₜ⋅Δr ⋅κₜ ⋅λ₀ - K_d ⋅Δr ⋅κₜ ⋅λ₀  + K_d⋅Pᵢₙ⋅aₑ\n",
       "\n",
       "          2⎞\n",
       "ₓ⋅Δr⋅κₜ⋅λ₀ ⎠"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr5 = collect(expr4, λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "078ea630-8fb0-46ed-a939-689818dfbbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\begin{equation*}0\\end{equation*}$\n"
      ],
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(expr5.coeff(λ, 4))\n",
    "expr5.coeff(λ, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "67d1c776-a0c5-4d91-8ed6-854deb76d14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_M*K_d*Δr*κ_t*λ_0 - K_d^2*Δr^2*κ_t^2 + K_d*V_0*Δr*κ_t\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\begin{equation*}- K_{d} Δr κ_{t} \\left(- K_{M} λ_{0} + K_{d} Δr κ_{t} - V_{0}\\right)\\end{equation*}$\n"
      ],
      "text/plain": [
       "-K_d⋅Δr⋅κₜ⋅(-K_M⋅λ₀ + K_d⋅Δr⋅κₜ - V₀)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(expr5.coeff(λ, 3))\n",
    "factor(expr5.coeff(λ, 3), K_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e148c2b9-f245-490d-8fab-41f64f201b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_M*K_d*P_out*Δr*κ_t*λ_0 - K_M*K_d*Δr*κ_t*λ_0^2 + K_M*P_in*a_ex*λ_0^2 - K_d^2*P_out*Δr^2*κ_t^2 + 2*K_d^2*Δr^2*κ_t^2*λ_0 - K_d*P_in*a_ex*Δr*κ_t*λ_0 - K_d*V_0*Δr*κ_t*λ_0\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\begin{equation*}K_{M} P_{in} a_{ex} λ_{0}^{2} - K_{d}^{2} \\left(P_{out} Δr^{2} κ_{t}^{2} - 2 Δr^{2} κ_{t}^{2} λ_{0}\\right) - K_{d} \\left(- K_{M} P_{out} Δr κ_{t} λ_{0} + K_{M} Δr κ_{t} λ_{0}^{2} + P_{in} a_{ex} Δr κ_{t} λ_{0} + V_{0} Δr κ_{t} λ_{0}\\right)\\end{equation*}$\n"
      ],
      "text/plain": [
       "              2      2 ⎛       2   2       2   2   ⎞       ⎛                  \n",
       "K_M⋅Pᵢₙ⋅aₑₓ⋅λ₀  - K_d ⋅⎝Pₒᵤₜ⋅Δr ⋅κₜ  - 2⋅Δr ⋅κₜ ⋅λ₀⎠ - K_d⋅⎝-K_M⋅Pₒᵤₜ⋅Δr⋅κₜ⋅λ₀\n",
       "\n",
       "               2                                 ⎞\n",
       " + K_M⋅Δr⋅κₜ⋅λ₀  + Pᵢₙ⋅aₑₓ⋅Δr⋅κₜ⋅λ₀ + V₀⋅Δr⋅κₜ⋅λ₀⎠"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(expr5.coeff(λ, 2))\n",
    "factor(expr5.coeff(λ, 2), K_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd88f485-4b40-44d3-badf-a2db6916f4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-K_M*K_d*P_out*Δr*κ_t*λ_0^2 + 2*K_d^2*P_out*Δr^2*κ_t^2*λ_0 - K_d^2*Δr^2*κ_t^2*λ_0^2 + K_d*P_in*a_ex*Δr*κ_t*λ_0^2\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\begin{equation*}K_{d} Δr κ_{t} λ_{0} \\left(- K_{M} P_{out} λ_{0} + K_{d} \\left(2 P_{out} Δr κ_{t} - Δr κ_{t} λ_{0}\\right) + P_{in} a_{ex} λ_{0}\\right)\\end{equation*}$\n"
      ],
      "text/plain": [
       "K_d⋅Δr⋅κₜ⋅λ₀⋅(-K_M⋅Pₒᵤₜ⋅λ₀ + K_d⋅(2⋅Pₒᵤₜ⋅Δr⋅κₜ - Δr⋅κₜ⋅λ₀) + Pᵢₙ⋅aₑₓ⋅λ₀)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(expr5.coeff(λ, 1))\n",
    "factor(expr5.coeff(λ, 1), K_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "048d2217-6ca1-47c2-b842-468accbca45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-K_d^2*P_out*Δr^2*κ_t^2*λ_0^2\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\begin{equation*}- K_{d}^{2} P_{out} Δr^{2} κ_{t}^{2} λ_{0}^{2}\\end{equation*}$\n"
      ],
      "text/plain": [
       "    2        2   2   2\n",
       "-K_d ⋅Pₒᵤₜ⋅Δr ⋅κₜ ⋅λ₀ "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(expr5.coeff(λ, 0))\n",
    "expr5.coeff(λ, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ee7694f2-3671-42b6-84b1-e9bd88711b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\begin{equation*}- K_{d}^{2} P_{out} Δr^{2} κ_{t}^{2} λ_{0}^{2} + λ^{3} \\left(K_{M} K_{d} Δr κ_{t} λ_{0} - K_{d}^{2} Δr^{2} κ_{t}^{2} + K_{d} V_{0} Δr κ_{t}\\right) + λ^{2} \\left(K_{M} K_{d} P_{out} Δr κ_{t} λ_{0} - K_{M} K_{d} Δr κ_{t} λ_{0}^{2} + K_{M} P_{in} a_{ex} λ_{0}^{2} - K_{d}^{2} P_{out} Δr^{2} κ_{t}^{2} + 2 K_{d}^{2} Δr^{2} κ_{t}^{2} λ_{0} - K_{d} P_{in} a_{ex} Δr κ_{t} λ_{0} - K_{d} V_{0} Δr κ_{t} λ_{0}\\right) + λ \\left(- K_{M} K_{d} P_{out} Δr κ_{t} λ_{0}^{2} + 2 K_{d}^{2} P_{out} Δr^{2} κ_{t}^{2} λ_{0} - K_{d}^{2} Δr^{2} κ_{t}^{2} λ_{0}^{2} + K_{d} P_{in} a_{ex} Δr κ_{t} λ_{0}^{2}\\right)\\end{equation*}$\n"
      ],
      "text/plain": [
       "     2        2   2   2    3 ⎛                      2   2   2               ⎞ \n",
       "- K_d ⋅Pₒᵤₜ⋅Δr ⋅κₜ ⋅λ₀  + λ ⋅⎝K_M⋅K_d⋅Δr⋅κₜ⋅λ₀ - K_d ⋅Δr ⋅κₜ  + K_d⋅V₀⋅Δr⋅κₜ⎠ \n",
       "\n",
       "   2 ⎛                                        2                 2      2      \n",
       "+ λ ⋅⎝K_M⋅K_d⋅Pₒᵤₜ⋅Δr⋅κₜ⋅λ₀ - K_M⋅K_d⋅Δr⋅κₜ⋅λ₀  + K_M⋅Pᵢₙ⋅aₑₓ⋅λ₀  - K_d ⋅Pₒᵤₜ⋅\n",
       "\n",
       "  2   2        2   2   2                                            ⎞     ⎛   \n",
       "Δr ⋅κₜ  + 2⋅K_d ⋅Δr ⋅κₜ ⋅λ₀ - K_d⋅Pᵢₙ⋅aₑₓ⋅Δr⋅κₜ⋅λ₀ - K_d⋅V₀⋅Δr⋅κₜ⋅λ₀⎠ + λ⋅⎝- K\n",
       "\n",
       "                    2        2        2   2         2   2   2   2             \n",
       "_M⋅K_d⋅Pₒᵤₜ⋅Δr⋅κₜ⋅λ₀  + 2⋅K_d ⋅Pₒᵤₜ⋅Δr ⋅κₜ ⋅λ₀ - K_d ⋅Δr ⋅κₜ ⋅λ₀  + K_d⋅Pᵢₙ⋅aₑ\n",
       "\n",
       "          2⎞\n",
       "ₓ⋅Δr⋅κₜ⋅λ₀ ⎠"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "69dd2108-d567-4948-b668-e1af749388a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solve_polynomial (generic function with 1 method)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function solve_polynomial(aex, λ0, κt, Kd, KM, j, V0, Δr)\n",
    "    c = zeros(4)\n",
    "    c1 = κt * Kd * Δr\n",
    "    c[4] = c1 * (KM * λ0 - c1 + V0)\n",
    "    c[3] = KM * j * aex * λ0^2 - c1^2 * (j - 2λ0) - c1 * λ0 * (-KM * j  + KM * λ0 + j * aex + V0)\n",
    "    c[2] = c1 * λ0 * (-KM * j * λ0 + c1 * (2j - λ0) + j * aex * λ0)\n",
    "    c[1] = -Kd^2*j*Δr^2*κt^2*λ0^2\n",
    "    pol = Polynomial(c)\n",
    "    return Polynomials.roots(pol)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f95af6c4-0aad-4b31-a725-7167166a5810",
   "metadata": {},
   "outputs": [],
   "source": [
    "_aex = 0  # µM\n",
    "_λ0 = 0.68  # h**-1\n",
    "_κt = 0.06  # µM**-1 h**-1\n",
    "_Kd = .1  # µM\n",
    "_KM = 100 # µM\n",
    "_j = 10# h**-1\n",
    "Pin = 10\n",
    "Pout = 3\n",
    "_V0 = 0\n",
    "_Δr = 46.5  # µM\n",
    "\n",
    "\n",
    "a_ex_range = [0, 1]\n",
    "sol_list = zeros(ComplexF64, 3, length(a_ex_range))\n",
    "for (i, x) in enumerate(a_ex_range)\n",
    "    # Pack parameters together\n",
    "    args = (x, _λ0, _κt, _Kd, _KM, _j, _V0, _Δr)\n",
    "    # Find roots\n",
    "    sol_list[:, i] = solve_polynomial(args...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9b6fbeec-2494-4325-a50e-832c83aa72a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{ComplexF64}:\n",
       "     -33.89338895304312 + 0.0im\n",
       " -0.0028014943665923423 + 0.0im\n",
       "    0.20062909641230975 + 0.0im"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_list[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72c8e5dd-dcbf-470f-aa71-ddc3a175a8af",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: scatter not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: scatter not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[21]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "p = scatter(\n",
    "    ylim=[0, 1],\n",
    "    xscale=:log,\n",
    "    legendtitle = \"V0\",\n",
    "    ylabel=\"λ/λ0\",\n",
    "    xlabel=\"a_ex\",\n",
    "    title=\"Is this the right font?\"\n",
    ")\n",
    "\n",
    "V_0_list = [0, 1000, 5000, 10000]\n",
    "for (_V0, c) in zip(V_0_list, palette(:BuPu_6)[2:end])\n",
    "    y = []\n",
    "    x = Float64[]\n",
    "    for i in 1:length(a_ex_range)\n",
    "        args = (a_ex_range[i], _λ0, _κt, _Kd, _KM, _j, _V0, _Δr)\n",
    "        solutions = solve_polynomial(args...)\n",
    "        _y = [imag(x) == 0 ? real(x)/_λ0 : missing for x in solutions]\n",
    "        push!(y, _y...)\n",
    "        _x = ones(length(_y)) .* a_ex_range[i]\n",
    "        push!(x, _x...)\n",
    "    end\n",
    "    scatter!(p, x, y, color=c, label=\"$_V0\")\n",
    "end\n",
    "savefig(p, \"res_model.pdf\")\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d60a49-3233-4633-aa1e-0b64df2668cc",
   "metadata": {},
   "source": [
    "## Writing Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9735d3b0-0ce5-4125-8472-ba23259cdd5e",
   "metadata": {},
   "source": [
    "Now we are going to write down the model in a Bayesian way and try out various priors.\n",
    "\n",
    "\\begin{align}\n",
    "\\lambda_0 &= 0.68 h^{-1},\\\\[.5em]\n",
    "\\kappa_t &= 0.06 \\mu M^{-1} h^{-1},\\\\[.5em]\n",
    "K_d &= 0.1 \\mu M,\\\\[.5em]\n",
    "K_M &= 10 \\mu M,\\\\[.5em]\n",
    "\\Delta r &= 46.5 \\mu M,\\\\[.5em]\n",
    "\\log j &\\sim \\text{Norm}(2, 2),\\\\[.5em]\n",
    "j &= 10^{\\log j} \\times 1 s^{-1},\\\\[.5em]\n",
    "\\log P_\\mathrm{in} &\\sim \\text{Norm}(2, 2),\\\\[.5em]\n",
    "P_\\mathrm{in} &= 10^{\\log P_\\mathrm{in}} \\times 1 s^{-1},\\\\[.5em]\n",
    "\\log P_\\mathrm{out} &\\sim \\text{Norm}(2, 2),\\\\[.5em]\n",
    "P_\\mathrm{out} &= 10^{\\log P_\\mathrm{out}} \\times 1 s^{-1},\\\\[.5em]\n",
    "\\log V_0 &\\sim \\text{Norm}(2, 2),\\\\[.5em]\n",
    "V_0  &= 10^{\\log V_0 } \\times 1 \\mu M s^{-1}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "57338bcc-1378-46c2-a110-29f1b42e6ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_growth (generic function with 3 methods)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@model function fit_growth(growth_rates, aex_arr)\n",
    "    \n",
    "    log_j ~ Normal(2, .2)\n",
    "    log_V0 ~ Normal(2, .2)\n",
    "    log_sigma ~ Normal(-3, 1)\n",
    "    \n",
    "    sigma = float(10^log_sigma)\n",
    "    j = 10^log_j\n",
    "    V0 = 10^log_V0\n",
    "    \n",
    "    λ0 = 0.68  \n",
    "    κt = 0.06\n",
    "    Kd = .1\n",
    "    KM = 10\n",
    "    Δr = 46.5\n",
    "    \n",
    "    for (i, aex) in enumerate(aex_arr)\n",
    "        λ = growth_rates[i]\n",
    "        println(i)\n",
    "        println(typeof(V0))\n",
    "        x = [aex, λ0, κt, Kd, KM, j, V0, Δr]\n",
    "        solutions = solve_polynomial(x)\n",
    "        \n",
    "        #y = [imag(x) == 0 ? real(x)/λ0 : missing for x in solutions]\n",
    "        #y = filter(x -> !ismissing(x) && (x > 0), y)\n",
    "        #if length(y) == 3\n",
    "            #deleteat!(y, 2)\n",
    "            #opt_y = y[argmin([(λ - root)^2 for root in y])]\n",
    "        #else\n",
    "            #opt_y = y[1]\n",
    "       #end\n",
    "        \n",
    "        #println(opt_y)\n",
    "        #println(typeof(opt_y))\n",
    "        #println()\n",
    "        #growth_rates[i] ~ Normal(opt_y / λ0, sigma)\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "681f4bb3-6176-45e4-a180-896ca98c983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Float64[]\n",
    "for i in 1:length(a_ex_range)\n",
    "    args = (a_ex_range[i], _λ0, _κt, _Kd, _KM, _j, 0, _Δr)\n",
    "    solutions = solve_polynomial(args...)\n",
    "    _y = [imag(x) == 0 ? real(x)/_λ0 : missing for x in solutions]\n",
    "    push!(y, _y[1])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9a280afe-43ce-4379-8102-a4cdc0f6a08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Float64\n",
      "2\n",
      "Float64\n",
      "3\n",
      "Float64\n",
      "4\n",
      "Float64\n",
      "5\n",
      "Float64\n",
      "6\n",
      "Float64\n",
      "7\n",
      "Float64\n",
      "8\n",
      "Float64\n",
      "9\n",
      "Float64\n",
      "10\n",
      "Float64\n",
      "11\n",
      "Float64\n",
      "12\n",
      "Float64\n",
      "13\n",
      "Float64\n",
      "14\n",
      "Float64\n",
      "15\n",
      "Float64\n",
      "16\n",
      "Float64\n",
      "17\n",
      "Float64\n",
      "18\n",
      "Float64\n",
      "19\n",
      "Float64\n",
      "20\n",
      "Float64\n",
      "21\n",
      "Float64\n",
      "22\n",
      "Float64\n",
      "23\n",
      "Float64\n",
      "24\n",
      "Float64\n",
      "25\n",
      "Float64\n",
      "26\n",
      "Float64\n",
      "27\n",
      "Float64\n",
      "28\n",
      "Float64\n",
      "29\n",
      "Float64\n",
      "30\n",
      "Float64\n",
      "31\n",
      "Float64\n",
      "32\n",
      "Float64\n",
      "33\n",
      "Float64\n",
      "34\n",
      "Float64\n",
      "35\n",
      "Float64\n",
      "36\n",
      "Float64\n",
      "37\n",
      "Float64\n",
      "38\n",
      "Float64\n",
      "39\n",
      "Float64\n",
      "40\n",
      "Float64\n",
      "41\n",
      "Float64\n",
      "42\n",
      "Float64\n",
      "43\n",
      "Float64\n",
      "44\n",
      "Float64\n",
      "45\n",
      "Float64\n",
      "46\n",
      "Float64\n",
      "47\n",
      "Float64\n",
      "48\n",
      "Float64\n",
      "49\n",
      "Float64\n",
      "50\n",
      "Float64\n",
      "51\n",
      "Float64\n",
      "52\n",
      "Float64\n",
      "53\n",
      "Float64\n",
      "54\n",
      "Float64\n",
      "55\n",
      "Float64\n",
      "56\n",
      "Float64\n",
      "57\n",
      "Float64\n",
      "58\n",
      "Float64\n",
      "59\n",
      "Float64\n",
      "60\n",
      "Float64\n",
      "61\n",
      "Float64\n",
      "62\n",
      "Float64\n",
      "63\n",
      "Float64\n",
      "64\n",
      "Float64\n",
      "65\n",
      "Float64\n",
      "66\n",
      "Float64\n",
      "67\n",
      "Float64\n",
      "68\n",
      "Float64\n",
      "69\n",
      "Float64\n",
      "70\n",
      "Float64\n",
      "71\n",
      "Float64\n",
      "72\n",
      "Float64\n",
      "73\n",
      "Float64\n",
      "74\n",
      "Float64\n",
      "75\n",
      "Float64\n",
      "76\n",
      "Float64\n",
      "77\n",
      "Float64\n",
      "78\n",
      "Float64\n",
      "79\n",
      "Float64\n",
      "80\n",
      "Float64\n",
      "81\n",
      "Float64\n",
      "82\n",
      "Float64\n",
      "83\n",
      "Float64\n",
      "84\n",
      "Float64\n",
      "85\n",
      "Float64\n",
      "86\n",
      "Float64\n",
      "87\n",
      "Float64\n",
      "88\n",
      "Float64\n",
      "89\n",
      "Float64\n",
      "90\n",
      "Float64\n",
      "91\n",
      "Float64\n",
      "92\n",
      "Float64\n",
      "93\n",
      "Float64\n",
      "94\n",
      "Float64\n",
      "95\n",
      "Float64\n",
      "96\n",
      "Float64\n",
      "97\n",
      "Float64\n",
      "98\n",
      "Float64\n",
      "99\n",
      "Float64\n",
      "100\n",
      "Float64\n",
      "101\n",
      "Float64\n",
      "102\n",
      "Float64\n",
      "103\n",
      "Float64\n",
      "104\n",
      "Float64\n",
      "105\n",
      "Float64\n",
      "106\n",
      "Float64\n",
      "107\n",
      "Float64\n",
      "108\n",
      "Float64\n",
      "109\n",
      "Float64\n",
      "110\n",
      "Float64\n",
      "111\n",
      "Float64\n",
      "112\n",
      "Float64\n",
      "113\n",
      "Float64\n",
      "114\n",
      "Float64\n",
      "115\n",
      "Float64\n",
      "116\n",
      "Float64\n",
      "117\n",
      "Float64\n",
      "118\n",
      "Float64\n",
      "119\n",
      "Float64\n",
      "120\n",
      "Float64\n",
      "121\n",
      "Float64\n",
      "1\n",
      "Float64\n",
      "2\n",
      "Float64\n",
      "3\n",
      "Float64\n",
      "4\n",
      "Float64\n",
      "5\n",
      "Float64\n",
      "6\n",
      "Float64\n",
      "7\n",
      "Float64\n",
      "8\n",
      "Float64\n",
      "9\n",
      "Float64\n",
      "10\n",
      "Float64\n",
      "11\n",
      "Float64\n",
      "12\n",
      "Float64\n",
      "13\n",
      "Float64\n",
      "14\n",
      "Float64\n",
      "15\n",
      "Float64\n",
      "16\n",
      "Float64\n",
      "17\n",
      "Float64\n",
      "18\n",
      "Float64\n",
      "19\n",
      "Float64\n",
      "20\n",
      "Float64\n",
      "21\n",
      "Float64\n",
      "22\n",
      "Float64\n",
      "23\n",
      "Float64\n",
      "24\n",
      "Float64\n",
      "25\n",
      "Float64\n",
      "26\n",
      "Float64\n",
      "27\n",
      "Float64\n",
      "28\n",
      "Float64\n",
      "29\n",
      "Float64\n",
      "30\n",
      "Float64\n",
      "31\n",
      "Float64\n",
      "32\n",
      "Float64\n",
      "33\n",
      "Float64\n",
      "34\n",
      "Float64\n",
      "35\n",
      "Float64\n",
      "36\n",
      "Float64\n",
      "37\n",
      "Float64\n",
      "38\n",
      "Float64\n",
      "39\n",
      "Float64\n",
      "40\n",
      "Float64\n",
      "41\n",
      "Float64\n",
      "42\n",
      "Float64\n",
      "43\n",
      "Float64\n",
      "44\n",
      "Float64\n",
      "45\n",
      "Float64\n",
      "46\n",
      "Float64\n",
      "47\n",
      "Float64\n",
      "48\n",
      "Float64\n",
      "49\n",
      "Float64\n",
      "50\n",
      "Float64\n",
      "51\n",
      "Float64\n",
      "52\n",
      "Float64\n",
      "53\n",
      "Float64\n",
      "54\n",
      "Float64\n",
      "55\n",
      "Float64\n",
      "56\n",
      "Float64\n",
      "57\n",
      "Float64\n",
      "58\n",
      "Float64\n",
      "59\n",
      "Float64\n",
      "60\n",
      "Float64\n",
      "61\n",
      "Float64\n",
      "62\n",
      "Float64\n",
      "63\n",
      "Float64\n",
      "64\n",
      "Float64\n",
      "65\n",
      "Float64\n",
      "66\n",
      "Float64\n",
      "67\n",
      "Float64\n",
      "68\n",
      "Float64\n",
      "69\n",
      "Float64\n",
      "70\n",
      "Float64\n",
      "71\n",
      "Float64\n",
      "72\n",
      "Float64\n",
      "73\n",
      "Float64\n",
      "74\n",
      "Float64\n",
      "75\n",
      "Float64\n",
      "76\n",
      "Float64\n",
      "77\n",
      "Float64\n",
      "78\n",
      "Float64\n",
      "79\n",
      "Float64\n",
      "80\n",
      "Float64\n",
      "81\n",
      "Float64\n",
      "82\n",
      "Float64\n",
      "83\n",
      "Float64\n",
      "84\n",
      "Float64\n",
      "85\n",
      "Float64\n",
      "86\n",
      "Float64\n",
      "87\n",
      "Float64\n",
      "88\n",
      "Float64\n",
      "89\n",
      "Float64\n",
      "90\n",
      "Float64\n",
      "91\n",
      "Float64\n",
      "92\n",
      "Float64\n",
      "93\n",
      "Float64\n",
      "94\n",
      "Float64\n",
      "95\n",
      "Float64\n",
      "96\n",
      "Float64\n",
      "97\n",
      "Float64\n",
      "98\n",
      "Float64\n",
      "99\n",
      "Float64\n",
      "100\n",
      "Float64\n",
      "101\n",
      "Float64\n",
      "102\n",
      "Float64\n",
      "103\n",
      "Float64\n",
      "104\n",
      "Float64\n",
      "105\n",
      "Float64\n",
      "106\n",
      "Float64\n",
      "107\n",
      "Float64\n",
      "108\n",
      "Float64\n",
      "109\n",
      "Float64\n",
      "110\n",
      "Float64\n",
      "111\n",
      "Float64\n",
      "112\n",
      "Float64\n",
      "113\n",
      "Float64\n",
      "114\n",
      "Float64\n",
      "115\n",
      "Float64\n",
      "116\n",
      "Float64\n",
      "117\n",
      "Float64\n",
      "118\n",
      "Float64\n",
      "119\n",
      "Float64\n",
      "120\n",
      "Float64\n",
      "121\n",
      "Float64\n",
      "1\n",
      "ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching eigvals!(::Matrix{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}})\n\u001b[0mClosest candidates are:\n\u001b[0m  eigvals!(\u001b[91m::SymTridiagonal{var\"#s832\", V} where {var\"#s832\"<:Union{Float32, Float64}, V<:AbstractVector{var\"#s832\"}}\u001b[39m) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/LinearAlgebra/src/tridiag.jl:293\n\u001b[0m  eigvals!(\u001b[91m::SymTridiagonal{var\"#s832\", V} where {var\"#s832\"<:Union{Float32, Float64}, V<:AbstractVector{var\"#s832\"}}\u001b[39m, \u001b[91m::UnitRange\u001b[39m) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/LinearAlgebra/src/tridiag.jl:296\n\u001b[0m  eigvals!(\u001b[91m::SymTridiagonal{var\"#s832\", V} where {var\"#s832\"<:Union{Float32, Float64}, V<:AbstractVector{var\"#s832\"}}\u001b[39m, \u001b[91m::Real\u001b[39m, \u001b[91m::Real\u001b[39m) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/LinearAlgebra/src/tridiag.jl:301\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching eigvals!(::Matrix{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}})\n\u001b[0mClosest candidates are:\n\u001b[0m  eigvals!(\u001b[91m::SymTridiagonal{var\"#s832\", V} where {var\"#s832\"<:Union{Float32, Float64}, V<:AbstractVector{var\"#s832\"}}\u001b[39m) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/LinearAlgebra/src/tridiag.jl:293\n\u001b[0m  eigvals!(\u001b[91m::SymTridiagonal{var\"#s832\", V} where {var\"#s832\"<:Union{Float32, Float64}, V<:AbstractVector{var\"#s832\"}}\u001b[39m, \u001b[91m::UnitRange\u001b[39m) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/LinearAlgebra/src/tridiag.jl:296\n\u001b[0m  eigvals!(\u001b[91m::SymTridiagonal{var\"#s832\", V} where {var\"#s832\"<:Union{Float32, Float64}, V<:AbstractVector{var\"#s832\"}}\u001b[39m, \u001b[91m::Real\u001b[39m, \u001b[91m::Real\u001b[39m) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/LinearAlgebra/src/tridiag.jl:301\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      "  [1] eigvals(A::Matrix{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}}; kws::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ LinearAlgebra /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/LinearAlgebra/src/eigen.jl:326",
      "  [2] eigvals(A::Matrix{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}})",
      "    @ LinearAlgebra /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/LinearAlgebra/src/eigen.jl:326",
      "  [3] roots(p::Polynomial{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}, :x}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ Polynomials ~/.julia/packages/Polynomials/Mu4EN/src/polynomials/standard-basis.jl:456",
      "  [4] roots(p::Polynomial{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}, :x})",
      "    @ Polynomials ~/.julia/packages/Polynomials/Mu4EN/src/polynomials/standard-basis.jl:438",
      "  [5] solve_polynomial(x::Vector{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}})",
      "    @ Main ./In[152]:10",
      "  [6] #453",
      "    @ ./In[192]:22 [inlined]",
      "  [7] (::var\"#453#454\")(__model__::DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, __varinfo__::DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}}, Vector{Set{DynamicPPL.Selector}}}}}, ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}}, __context__::DynamicPPL.SamplingContext{DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext, Random._GLOBAL_RNG}, growth_rates::Vector{Float64}, aex_arr::Vector{Float64})",
      "    @ Main ./none:0",
      "  [8] macro expansion",
      "    @ ~/.julia/packages/DynamicPPL/yvQQ0/src/model.jl:465 [inlined]",
      "  [9] _evaluate",
      "    @ ~/.julia/packages/DynamicPPL/yvQQ0/src/model.jl:448 [inlined]",
      " [10] evaluate_threadunsafe",
      "    @ ~/.julia/packages/DynamicPPL/yvQQ0/src/model.jl:421 [inlined]",
      " [11] (::DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext})(varinfo::DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}}, Vector{Set{DynamicPPL.Selector}}}}}, ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}}, context::DynamicPPL.SamplingContext{DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext, Random._GLOBAL_RNG})",
      "    @ DynamicPPL ~/.julia/packages/DynamicPPL/yvQQ0/src/model.jl:389",
      " [12] Model",
      "    @ ~/.julia/packages/DynamicPPL/yvQQ0/src/model.jl:383 [inlined]",
      " [13] Model",
      "    @ ~/.julia/packages/DynamicPPL/yvQQ0/src/model.jl:396 [inlined]",
      " [14] f",
      "    @ ~/.julia/packages/Turing/y0DW3/src/core/ad.jl:111 [inlined]",
      " [15] vector_mode_dual_eval",
      "    @ ~/.julia/packages/ForwardDiff/5gUap/src/apiutils.jl:37 [inlined]",
      " [16] vector_mode_gradient!(result::Vector{Float64}, f::Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, x::Vector{Float64}, cfg::ForwardDiff.GradientConfig{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3, Vector{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}}})",
      "    @ ForwardDiff ~/.julia/packages/ForwardDiff/5gUap/src/gradient.jl:113",
      " [17] gradient!",
      "    @ ~/.julia/packages/ForwardDiff/5gUap/src/gradient.jl:37 [inlined]",
      " [18] gradient!(result::Vector{Float64}, f::Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, x::Vector{Float64}, cfg::ForwardDiff.GradientConfig{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3, Vector{ForwardDiff.Dual{ForwardDiff.Tag{Turing.Core.var\"#f#1\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, Float64}, Float64, 3}}})",
      "    @ ForwardDiff ~/.julia/packages/ForwardDiff/5gUap/src/gradient.jl:35",
      " [19] gradient_logp(::Turing.Core.ForwardDiffAD{40}, θ::Vector{Float64}, vi::DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, model::DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, sampler::DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, ctx::DynamicPPL.DefaultContext)",
      "    @ Turing.Core ~/.julia/packages/Turing/y0DW3/src/core/ad.jl:121",
      " [20] gradient_logp (repeats 2 times)",
      "    @ ~/.julia/packages/Turing/y0DW3/src/core/ad.jl:83 [inlined]",
      " [21] ∂logπ∂θ",
      "    @ ~/.julia/packages/Turing/y0DW3/src/inference/hmc.jl:433 [inlined]",
      " [22] ∂H∂θ",
      "    @ ~/.julia/packages/AdvancedHMC/yd6UP/src/hamiltonian.jl:31 [inlined]",
      " [23] phasepoint",
      "    @ ~/.julia/packages/AdvancedHMC/yd6UP/src/hamiltonian.jl:76 [inlined]",
      " [24] phasepoint(rng::Random._GLOBAL_RNG, θ::Vector{Float64}, h::AdvancedHMC.Hamiltonian{AdvancedHMC.DiagEuclideanMetric{Float64, Vector{Float64}}, Turing.Inference.var\"#logπ#52\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}}, Turing.Inference.var\"#∂logπ∂θ#51\"{DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}}})",
      "    @ AdvancedHMC ~/.julia/packages/AdvancedHMC/yd6UP/src/hamiltonian.jl:153",
      " [25] initialstep(rng::Random._GLOBAL_RNG, model::DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, spl::DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, vi::DynamicPPL.TypedVarInfo{NamedTuple{(:log_j, :log_V0, :log_sigma), Tuple{DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_j, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_j, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_V0, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_V0, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:log_sigma, Tuple{}}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:log_sigma, Tuple{}}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}}, Float64}; init_params::Nothing, nadapts::Int64, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ Turing.Inference ~/.julia/packages/Turing/y0DW3/src/inference/hmc.jl:167",
      " [26] step(rng::Random._GLOBAL_RNG, model::DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, spl::DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}; resume_from::Nothing, kwargs::Base.Iterators.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:nadapts,), Tuple{Int64}}})",
      "    @ DynamicPPL ~/.julia/packages/DynamicPPL/yvQQ0/src/sampler.jl:87",
      " [27] macro expansion",
      "    @ ~/.julia/packages/AbstractMCMC/BPJCW/src/sample.jl:123 [inlined]",
      " [28] macro expansion",
      "    @ ~/.julia/packages/ProgressLogging/6KXlp/src/ProgressLogging.jl:328 [inlined]",
      " [29] (::AbstractMCMC.var\"#21#22\"{Bool, String, Nothing, Int64, Int64, Base.Iterators.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:nadapts,), Tuple{Int64}}}, Random._GLOBAL_RNG, DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, Int64, Int64})()",
      "    @ AbstractMCMC ~/.julia/packages/AbstractMCMC/BPJCW/src/logging.jl:11",
      " [30] with_logstate(f::Function, logstate::Any)",
      "    @ Base.CoreLogging ./logging.jl:491",
      " [31] with_logger(f::Function, logger::LoggingExtras.TeeLogger{Tuple{LoggingExtras.EarlyFilteredLogger{ConsoleProgressMonitor.ProgressLogger, AbstractMCMC.var\"#1#3\"{Module}}, LoggingExtras.EarlyFilteredLogger{Base.CoreLogging.SimpleLogger, AbstractMCMC.var\"#2#4\"{Module}}}})",
      "    @ Base.CoreLogging ./logging.jl:603",
      " [32] with_progresslogger(f::Function, _module::Module, logger::Base.CoreLogging.SimpleLogger)",
      "    @ AbstractMCMC ~/.julia/packages/AbstractMCMC/BPJCW/src/logging.jl:34",
      " [33] macro expansion",
      "    @ ~/.julia/packages/AbstractMCMC/BPJCW/src/logging.jl:10 [inlined]",
      " [34] mcmcsample(rng::Random._GLOBAL_RNG, model::DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, sampler::DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, N::Int64; progress::Bool, progressname::String, callback::Nothing, discard_initial::Int64, thinning::Int64, chain_type::Type, kwargs::Base.Iterators.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:nadapts,), Tuple{Int64}}})",
      "    @ AbstractMCMC ~/.julia/packages/AbstractMCMC/BPJCW/src/sample.jl:114",
      " [35] sample(rng::Random._GLOBAL_RNG, model::DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, sampler::DynamicPPL.Sampler{NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}}, N::Int64; chain_type::Type, resume_from::Nothing, progress::Bool, nadapts::Int64, discard_adapt::Bool, discard_initial::Int64, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ Turing.Inference ~/.julia/packages/Turing/y0DW3/src/inference/hmc.jl:133",
      " [36] sample",
      "    @ ~/.julia/packages/Turing/y0DW3/src/inference/hmc.jl:116 [inlined]",
      " [37] #sample#2",
      "    @ ~/.julia/packages/Turing/y0DW3/src/inference/Inference.jl:142 [inlined]",
      " [38] sample",
      "    @ ~/.julia/packages/Turing/y0DW3/src/inference/Inference.jl:142 [inlined]",
      " [39] #sample#1",
      "    @ ~/.julia/packages/Turing/y0DW3/src/inference/Inference.jl:132 [inlined]",
      " [40] sample(model::DynamicPPL.Model{var\"#453#454\", (:growth_rates, :aex_arr), (), (), Tuple{Vector{Float64}, Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, alg::NUTS{Turing.Core.ForwardDiffAD{40}, (), AdvancedHMC.DiagEuclideanMetric}, N::Int64)",
      "    @ Turing.Inference ~/.julia/packages/Turing/y0DW3/src/inference/Inference.jl:132",
      " [41] top-level scope",
      "    @ In[194]:1",
      " [42] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [43] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "chn = sample(fit_growth(y, a_ex_range), NUTS(0.65), 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b29fa9e4-83d7-44a6-a386-a0beadcf4c08",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: chn not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: chn not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ :0",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "chn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "45353c79-4d56-4e04-af2b-bfa8190b399f",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: ForwardDiff not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: ForwardDiff not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/REPL/src/docview.jl:469",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] execute_request(socket::ZMQ.Socket, msg::IJulia.Msg)",
      "   @ IJulia ~/.julia/packages/IJulia/e8kqU/src/execute_request.jl:64",
      " [4] #invokelatest#2",
      "   @ ./essentials.jl:708 [inlined]",
      " [5] invokelatest",
      "   @ ./essentials.jl:706 [inlined]",
      " [6] eventloop(socket::ZMQ.Socket)",
      "   @ IJulia ~/.julia/packages/IJulia/e8kqU/src/eventloop.jl:8",
      " [7] (::IJulia.var\"#15#18\")()",
      "   @ IJulia ./task.jl:406"
     ]
    }
   ],
   "source": [
    "?ForwardDiff.Dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b52bd5c2-52cb-4ba3-9006-4f85b007482d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1m!\u001b[22m \u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "eigvals!(A; permute::Bool=true, scale::Bool=true, sortby) -> values\n",
       "\\end{verbatim}\n",
       "Same as \\href{@ref}{\\texttt{eigvals}}, but saves space by overwriting the input \\texttt{A}, instead of creating a copy. The \\texttt{permute}, \\texttt{scale}, and \\texttt{sortby} keywords are the same as for \\href{@ref}{\\texttt{eigen}}.\n",
       "\n",
       "\\begin{quote}\n",
       "\\textbf{note}\n",
       "\n",
       "Note\n",
       "\n",
       "The input matrix \\texttt{A} will not contain its eigenvalues after \\texttt{eigvals!} is called on it - \\texttt{A} is used as a workspace.\n",
       "\n",
       "\\end{quote}\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> A = [1. 2.; 3. 4.]\n",
       "2×2 Matrix{Float64}:\n",
       " 1.0  2.0\n",
       " 3.0  4.0\n",
       "\n",
       "julia> eigvals!(A)\n",
       "2-element Vector{Float64}:\n",
       " -0.3722813232690143\n",
       "  5.372281323269014\n",
       "\n",
       "julia> A\n",
       "2×2 Matrix{Float64}:\n",
       " -0.372281  -1.0\n",
       "  0.0        5.37228\n",
       "\\end{verbatim}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "eigvals!(A, B; sortby) -> values\n",
       "\\end{verbatim}\n",
       "Same as \\href{@ref}{\\texttt{eigvals}}, but saves space by overwriting the input \\texttt{A} (and \\texttt{B}), instead of creating copies.\n",
       "\n",
       "\\begin{quote}\n",
       "\\textbf{note}\n",
       "\n",
       "Note\n",
       "\n",
       "The input matrices \\texttt{A} and \\texttt{B} will not contain their eigenvalues after \\texttt{eigvals!} is called. They are used as workspaces.\n",
       "\n",
       "\\end{quote}\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> A = [1. 0.; 0. -1.]\n",
       "2×2 Matrix{Float64}:\n",
       " 1.0   0.0\n",
       " 0.0  -1.0\n",
       "\n",
       "julia> B = [0. 1.; 1. 0.]\n",
       "2×2 Matrix{Float64}:\n",
       " 0.0  1.0\n",
       " 1.0  0.0\n",
       "\n",
       "julia> eigvals!(A, B)\n",
       "2-element Vector{ComplexF64}:\n",
       " 0.0 - 1.0im\n",
       " 0.0 + 1.0im\n",
       "\n",
       "julia> A\n",
       "2×2 Matrix{Float64}:\n",
       " -0.0  -1.0\n",
       "  1.0  -0.0\n",
       "\n",
       "julia> B\n",
       "2×2 Matrix{Float64}:\n",
       " 1.0  0.0\n",
       " 0.0  1.0\n",
       "\\end{verbatim}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "eigvals!(A::Union{SymTridiagonal, Hermitian, Symmetric}, irange::UnitRange) -> values\n",
       "\\end{verbatim}\n",
       "Same as \\href{@ref}{\\texttt{eigvals}}, but saves space by overwriting the input \\texttt{A}, instead of creating a copy. \\texttt{irange} is a range of eigenvalue \\emph{indices} to search for - for instance, the 2nd to 8th eigenvalues.\n",
       "\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "eigvals!(A::Union{SymTridiagonal, Hermitian, Symmetric}, vl::Real, vu::Real) -> values\n",
       "\\end{verbatim}\n",
       "Same as \\href{@ref}{\\texttt{eigvals}}, but saves space by overwriting the input \\texttt{A}, instead of creating a copy. \\texttt{vl} is the lower bound of the interval to search for eigenvalues, and \\texttt{vu} is the upper bound.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "eigvals!(A; permute::Bool=true, scale::Bool=true, sortby) -> values\n",
       "```\n",
       "\n",
       "Same as [`eigvals`](@ref), but saves space by overwriting the input `A`, instead of creating a copy. The `permute`, `scale`, and `sortby` keywords are the same as for [`eigen`](@ref).\n",
       "\n",
       "!!! note\n",
       "    The input matrix `A` will not contain its eigenvalues after `eigvals!` is called on it - `A` is used as a workspace.\n",
       "\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> A = [1. 2.; 3. 4.]\n",
       "2×2 Matrix{Float64}:\n",
       " 1.0  2.0\n",
       " 3.0  4.0\n",
       "\n",
       "julia> eigvals!(A)\n",
       "2-element Vector{Float64}:\n",
       " -0.3722813232690143\n",
       "  5.372281323269014\n",
       "\n",
       "julia> A\n",
       "2×2 Matrix{Float64}:\n",
       " -0.372281  -1.0\n",
       "  0.0        5.37228\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "eigvals!(A, B; sortby) -> values\n",
       "```\n",
       "\n",
       "Same as [`eigvals`](@ref), but saves space by overwriting the input `A` (and `B`), instead of creating copies.\n",
       "\n",
       "!!! note\n",
       "    The input matrices `A` and `B` will not contain their eigenvalues after `eigvals!` is called. They are used as workspaces.\n",
       "\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> A = [1. 0.; 0. -1.]\n",
       "2×2 Matrix{Float64}:\n",
       " 1.0   0.0\n",
       " 0.0  -1.0\n",
       "\n",
       "julia> B = [0. 1.; 1. 0.]\n",
       "2×2 Matrix{Float64}:\n",
       " 0.0  1.0\n",
       " 1.0  0.0\n",
       "\n",
       "julia> eigvals!(A, B)\n",
       "2-element Vector{ComplexF64}:\n",
       " 0.0 - 1.0im\n",
       " 0.0 + 1.0im\n",
       "\n",
       "julia> A\n",
       "2×2 Matrix{Float64}:\n",
       " -0.0  -1.0\n",
       "  1.0  -0.0\n",
       "\n",
       "julia> B\n",
       "2×2 Matrix{Float64}:\n",
       " 1.0  0.0\n",
       " 0.0  1.0\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "eigvals!(A::Union{SymTridiagonal, Hermitian, Symmetric}, irange::UnitRange) -> values\n",
       "```\n",
       "\n",
       "Same as [`eigvals`](@ref), but saves space by overwriting the input `A`, instead of creating a copy. `irange` is a range of eigenvalue *indices* to search for - for instance, the 2nd to 8th eigenvalues.\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "eigvals!(A::Union{SymTridiagonal, Hermitian, Symmetric}, vl::Real, vu::Real) -> values\n",
       "```\n",
       "\n",
       "Same as [`eigvals`](@ref), but saves space by overwriting the input `A`, instead of creating a copy. `vl` is the lower bound of the interval to search for eigenvalues, and `vu` is the upper bound.\n"
      ],
      "text/plain": [
       "\u001b[36m  eigvals!(A; permute::Bool=true, scale::Bool=true, sortby) -> values\u001b[39m\n",
       "\n",
       "  Same as \u001b[36meigvals\u001b[39m, but saves space by overwriting the input \u001b[36mA\u001b[39m, instead of\n",
       "  creating a copy. The \u001b[36mpermute\u001b[39m, \u001b[36mscale\u001b[39m, and \u001b[36msortby\u001b[39m keywords are the same as for\n",
       "  \u001b[36meigen\u001b[39m.\n",
       "\n",
       "\u001b[36m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[36m\u001b[1mNote\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  The input matrix \u001b[36mA\u001b[39m will not contain its eigenvalues after \u001b[36meigvals!\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  is called on it - \u001b[36mA\u001b[39m is used as a workspace.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> A = [1. 2.; 3. 4.]\u001b[39m\n",
       "\u001b[36m  2×2 Matrix{Float64}:\u001b[39m\n",
       "\u001b[36m   1.0  2.0\u001b[39m\n",
       "\u001b[36m   3.0  4.0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> eigvals!(A)\u001b[39m\n",
       "\u001b[36m  2-element Vector{Float64}:\u001b[39m\n",
       "\u001b[36m   -0.3722813232690143\u001b[39m\n",
       "\u001b[36m    5.372281323269014\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> A\u001b[39m\n",
       "\u001b[36m  2×2 Matrix{Float64}:\u001b[39m\n",
       "\u001b[36m   -0.372281  -1.0\u001b[39m\n",
       "\u001b[36m    0.0        5.37228\u001b[39m\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  eigvals!(A, B; sortby) -> values\u001b[39m\n",
       "\n",
       "  Same as \u001b[36meigvals\u001b[39m, but saves space by overwriting the input \u001b[36mA\u001b[39m (and \u001b[36mB\u001b[39m), instead\n",
       "  of creating copies.\n",
       "\n",
       "\u001b[36m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[36m\u001b[1mNote\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  The input matrices \u001b[36mA\u001b[39m and \u001b[36mB\u001b[39m will not contain their eigenvalues\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  after \u001b[36meigvals!\u001b[39m is called. They are used as workspaces.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> A = [1. 0.; 0. -1.]\u001b[39m\n",
       "\u001b[36m  2×2 Matrix{Float64}:\u001b[39m\n",
       "\u001b[36m   1.0   0.0\u001b[39m\n",
       "\u001b[36m   0.0  -1.0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> B = [0. 1.; 1. 0.]\u001b[39m\n",
       "\u001b[36m  2×2 Matrix{Float64}:\u001b[39m\n",
       "\u001b[36m   0.0  1.0\u001b[39m\n",
       "\u001b[36m   1.0  0.0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> eigvals!(A, B)\u001b[39m\n",
       "\u001b[36m  2-element Vector{ComplexF64}:\u001b[39m\n",
       "\u001b[36m   0.0 - 1.0im\u001b[39m\n",
       "\u001b[36m   0.0 + 1.0im\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> A\u001b[39m\n",
       "\u001b[36m  2×2 Matrix{Float64}:\u001b[39m\n",
       "\u001b[36m   -0.0  -1.0\u001b[39m\n",
       "\u001b[36m    1.0  -0.0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> B\u001b[39m\n",
       "\u001b[36m  2×2 Matrix{Float64}:\u001b[39m\n",
       "\u001b[36m   1.0  0.0\u001b[39m\n",
       "\u001b[36m   0.0  1.0\u001b[39m\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  eigvals!(A::Union{SymTridiagonal, Hermitian, Symmetric}, irange::UnitRange) -> values\u001b[39m\n",
       "\n",
       "  Same as \u001b[36meigvals\u001b[39m, but saves space by overwriting the input \u001b[36mA\u001b[39m, instead of\n",
       "  creating a copy. \u001b[36mirange\u001b[39m is a range of eigenvalue \u001b[4mindices\u001b[24m to search for - for\n",
       "  instance, the 2nd to 8th eigenvalues.\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  eigvals!(A::Union{SymTridiagonal, Hermitian, Symmetric}, vl::Real, vu::Real) -> values\u001b[39m\n",
       "\n",
       "  Same as \u001b[36meigvals\u001b[39m, but saves space by overwriting the input \u001b[36mA\u001b[39m, instead of\n",
       "  creating a copy. \u001b[36mvl\u001b[39m is the lower bound of the interval to search for\n",
       "  eigenvalues, and \u001b[36mvu\u001b[39m is the upper bound."
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?eigvals!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e5464-f0d5-4685-9ae0-534e87662c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
